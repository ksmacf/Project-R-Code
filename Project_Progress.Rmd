---
title: "Project Progress"
author: "Kenji Macfarlane ID:26006480"
date: "22/08/2019"
output: html_document
---

```{r setup, include=FALSE, eval = FALSE, echo = TRUE, tidy = TRUE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
# Load necessary libraries
library(tidyverse)
library(gridExtra)
library(dplyr)
library(caret)
library(xgboost)
library(h2o)
rm(list = ls(all.names = TRUE))
```

This section of code obtains the full set of data by data wrangling for the signal (stops) and background (tops).
0) The background data: tops (a single complete set.)
```{r}
# Load the data of interest
topData <- read.delim(file = "/home/user1/Desktop/Root files/ttbar1m.txt", sep = ",")

# Remove Electrons and Muons so that we have ONE lepton in each decay
topData_rmv <- topData %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs
ttbarlepPT_check <- summary(topData_rmv$Electron.PT_1==topData_rmv$Muon.PT_1) # Check if PT1 for E and M are different at each entry

# Data wrangling with Leptons
topData_rmv <- topData_rmv %>%
  mutate(
  Lepton.PT = Electron.PT_1 + Muon.PT_1,
  Lepton.Eta = Electron.Eta_1 + Muon.Eta_1,
  Lepton.Phi = Electron.Phi_1 + Muon.Phi_1,
  Lepton.Type = as.numeric(replace(Electron.PT_1, Electron.PT_1 > 0, 1)) + # 1 for Electrons
  as.numeric(replace(Muon.PT_1, Muon.PT_1 > 0, 2)), # 2 for Muons
  Signal = rep(0,nrow(topData_rmv))
  ) %>%
  select(-grep(pattern="^Electron|^Muon",colnames(topData_rmv)))

topData_rmv <- topData_rmv[-seq(230001,nrow(topData_rmv), by = 1),]
```

1) Stop benchmark 1 $ \tilde{t}= \text{TeV}, \chi_1^0 = \text{GeV} $.
```{r}
# Load the data of interest
stopbm1 <- read.delim(file = "/home/user1/Desktop/Root files/benchmark_01.txt", sep = ",")

# Remove Electrons and Muons so that we have ONE lepton in each decay
stopbm1_rmv <- stopbm1 %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs
lepPT_check <- summary(stopbm1_rmv$Electron.PT_1==stopbm1_rmv$Muon.PT_1) # Check if PT1 for E and M are different at each entry

# Data wrangling with Leptons
stopbm1_rmv <- stopbm1_rmv %>%
  mutate(
  Lepton.PT = Electron.PT_1 + Muon.PT_1,
  Lepton.Eta = Electron.Eta_1 + Muon.Eta_1,
  Lepton.Phi = Electron.Phi_1 + Muon.Phi_1,
  Lepton.Type = as.numeric(replace(Electron.PT_1, Electron.PT_1 > 0, 1)) + # 1 for Electrons
  as.numeric(replace(Muon.PT_1, Muon.PT_1 > 0, 2)), # 2 for Muons
  Signal = rep(1,nrow(stopbm1_rmv))
  ) %>%
  select(-grep(pattern="^Electron|^Muon",colnames(stopbm1_rmv)))

stopbm1_rmv <- stopbm1_rmv[-seq(230001,nrow(stopbm1_rmv), by = 1),]
```

Combine the data
- Benchmark01
```{r}
# Combine the stop and top data for a complete set
Data_benchmark01 <- rbind.data.frame(stopbm1_rmv, topData_rmv)
Data_benchmark01 <- Data_benchmark01[sample(nrow(Data_benchmark01)),]

## Free up some space
rm(stopbm1, topData)
```

Using the h2o package, we can can split the data set into training and test sets
```{r, message=FALSE}
# Run AutoML to find the possibly best model for this
h2o.init()
DD_h2oVer <- as.h2o(Data_benchmark01)
n_seed <- sample(1:1000000001, 1, replace=T)
h_split <- h2o.splitFrame(DD_h2oVer, ratios = 0.75, seed = n_seed)
h_train <- h_split[[1]] # 75% for modelling
h_test <- h_split[[2]]
features <- setdiff(colnames(Data_benchmark01), "Signal")
```

Within the h2o package, there is a function called "h2o.automl" which trains many models in order to obtain the best possible classifier.
Number 1), with a k-fold cross-validation of k=5 and testing 20 models... 
```{r}
automl1 = h2o.automl(x = features,
                    y = "Signal",
                    training_frame = h_train,
                    nfolds = 5,                     # 5-fold Cross-Validation
                    max_models = 20,                # Max number of models
                    stopping_metric = "RMSE",       # Metric to optimize
                    project_name = "automl_stop_search", # Specify a name so you can add more models later
                    seed = n_seed) 
check1 <- automl1@leaderboard
check1
```
Produced a result where a Stacking Ensemble was said to be best.

Number 2), with a k-fold cross-validation of k=10 and testing 100 models... 
```{r}
automl2 = h2o.automl(x = features,
                    y = "Signal",
                    training_frame = h_train,
                    nfolds = 10,                     # 5-fold Cross-Validation
                    max_models = 100,                # Max number of models
                    stopping_metric = "RMSE",       # Metric to optimize
                    project_name = "automl_stop_search", # Specify a name so you can add more models later
                    seed = n_seed) 
check2 <- automl2@leaderboard
check2
```
Number 3), with a k-fold cross-validation of k=10 and testing 200 models... 
```{r}
automl3 = h2o.automl(x = features,
                    y = "Signal",
                    training_frame = h_train,
                    nfolds = 10,                     # 5-fold Cross-Validation
                    max_models = 200,                # Max number of models
                    stopping_metric = "RMSE",       # Metric to optimize
                    project_name = "automl_stop_search", # Specify a name so you can add more models later
                    seed = n_seed) 
check3 <- automl3@leaderboard
check3
```

Build an XGBoost model according to automl (Ensemble methods are not to be considered).
```{r}
# Partition the given data in order to cross validate later
set.seed(sample(1:1000000001, 1, replace=T))
tr_indx <- createDataPartition(Data_benchmark01$Signal, p = 2/3)$Resample1
true_train <- Data_benchmark01[tr_indx, ]
true_test <- Data_benchmark01[-tr_indx, ]

set.seed(sample(1:1000000001, 1, replace=T))
tr_indx2 <- createDataPartition(true_train$Signal, p = 0.75)$Resample1
part_train <- true_train[tr_indx2, ]
part_test <- true_test[-tr_indx2, ]

# Set parameters etc
tr_M <- model.matrix(~. + 0, data = part_train %>% select(-Signal))
ts_M <- model.matrix(~. + 0, data = part_test %>% select(-Signal))
tr_lab <- part_train$Signal
ts_lab <- part_test$Signal
xgb_tr <- xgb.DMatrix(data = tr_M, label = tr_lab)
xgb_ts <- xgb.DMatrix(data = ts_M, label = ts_lab)

tr_test <- xgb.train(booster = "gbtree", objective = "binary:logistic", data = xgb_tr, nrounds = 200, max_depth = 6, eval_metric = "merror")
pred_test <- predict(tr_test, xgb_ts)
for (i in 1:NROW(pred_test)){
  if (pred_test[i] < 0.5){
       pred_test[i] = 0
     } else {
       pred_test[i] = 1
     }
}
confusionMatrix(table(pred_test, part_test$Signal))
```

Find the most optimal parameter
```{r}
param <- list(booster = "gbtree", objective = "multi:softmax", num_class = 2)

new_param <- expand.grid(
  nrounds = seq(from = 50, to = 250, by = 50),
  eta = seq(from = 0.1, to = 0.5, by = 0.1),
  max_depth = 4:8, 
  eval_metric = c("merror")
)

new_param <- new_param %>%
  mutate(!!! param)

#rm(lepPT_check, ttbarlepPT_check, tr_indx, tr_indx2, Data_benchmark01, stopbm1, stopbm1_rmv, topData, topData_rmv)

# Perform xgboost cv and extract minimum test MSE mean from each xgbcv
xgbcv_result <- matrix(nrow = NROW(new_param), ncol = 2) 
for (i in 1:NROW(new_param)){
  xgbcv <- 
    xgb.cv(params = new_param[i,], data = xgb_tr, nrounds = new_param[i,1],
           nfold = 10, showsd = T, stratified = T, print_every_n = 10, early_stopping_round = 20,
           maximize = F)
  xgbcv_result[i,1] <- min(xgbcv$evaluation_log$test_merror_mean)
  xgbcv_result[i,2] <- xgbcv$best_iteration
  rm(xgbcv)
}


#### row/list number of the best xgbcv
best_xgbcv <- which.min(xgbcv_result[,1])

best_param <- new_param[best_xgbcv,]

# train on partitioned set
tr_test <- xgb.train(params = best_param, data = xgb_tr, nrounds =xgbcv_result[best_xgbcv,2])
pred_test <- predict(tr_test, xgb_ts)
confusionMatrix(table(pred_test, part_test$Signal))

# train on original training set
bm01_tr <- model.matrix(~. + 0, data = true_train %>% select(-Signal))
#ts_M <- model.matrix(~. + 0, data = tr_ts %>% select(-outcome))

xgb_bm01 <- xgb.DMatrix(data = bm01_tr, label = true_train$Signal)
#xgb_ts <- xgb.DMatrix(data = ts_M, label = tr_ts$outcome)

tr_xgb <- xgb.train(params = best_param, 
          data = xgb_bm01, nrounds = xgbcv[[best_xgbcv]]$best_iteration)

# test error after prediction
bm01_ts <- model.matrix(~. + 0, data = bm01_ts %>% select(-Signal))
ts_xgbM <- xgb.DMatrix(data = bm01_ts %>% select(-Signal))
xgbpred <- predict(tr_xgb, ts_xgbM)
```




Using the h2o version to see if it doesn't crash...
```{r}
h2o.init()

Data_benchmark01["offset"] <- log(Data_benchmark01["Signal"])
Data_benchmark01[,"Signal"] <- as.factor(Data_benchmark01[,"Signal"])

# Partition the given data in order to cross validate later
set.seed(sample(1:1000000001, 1, replace=T))
tr_indx <- createDataPartition(Data_benchmark01$Signal, p = 2/3)$Resample1
true_train <- Data_benchmark01[tr_indx, ]
true_test <- Data_benchmark01[-tr_indx, ]

set.seed(sample(1:1000000001, 1, replace=T))
tr_indx2 <- createDataPartition(true_train$Signal, p = 0.75)$Resample1



true_tr <- as.h2o(true_train, destination_frame = "true_train")
true_ts <- as.h2o(true_test, destination_frame = "true_test")
part_train <- as.h2o(true_train[tr_indx2, ], destination_frame = "part_train")
part_test <- as.h2o(true_test[-tr_indx2, ], destination_frame = "part_test")


param <- expand.grid(
  ntrees = seq(from = 40, to = 80, by = 10),
  learn_rate = seq(from = 0.1, to = 0.5, by = 0.1),
  max_depth = 4:8, 
  stopping_metric = c("mse", "rmse", "logloss", "mae", "rmsle")
)

fold_numbers <- h2o.kfold_column(part_train, nfolds=10)
fold_numbers2 <- h2o.kfold_column(part_test, nfolds=10)

# rename the column "fold_numbers"
names(fold_numbers) <- "fold_numbers"

# rename the column "fold_numbers"
names(fold_numbers2) <- "fold_numbers"

part_train <- h2o.cbind(part_train,fold_numbers)
part_test <- h2o.cbind(part_test,fold_numbers2)

# Perform xgboost cv
xgb <- vector("list", NROW(param)) 
for (i in 1:NROW(param)){
 xgb[[i]] <- h2o.xgboost(y = "Signal",
                         x = 1:40,
                         training_frame = part_train,
                         validation_frame = part_test,
                         model_id = "model",
                         param[i,],
                         stopping_rounds = 5,
                         distribution = "bernoulli",
                         score_tree_interval = 1,
                         score_each_iteration = TRUE,
                         nfolds = 10,
                         fold_assignment = "AUTO",
                         fold_column = "fold_numbers",
                         ignore_const_cols = TRUE,
                         offset_column = NULL,
                         weights_column = NULL,
                         keep_cross_validation_models = TRUE,
                         keep_cross_validation_predictions = FALSE,
                         keep_cross_validation_fold_assignment = FALSE,
                         tree_method = "hist",
                         grow_policy = "lossguide",
                         booster = "gbtree",
                         gamma = 0.0,
                         )
}


#Preds <- h2o.predict(xgb, true_test)

```
