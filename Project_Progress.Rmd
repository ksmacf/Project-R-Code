---
title: "Project Progress"
author: "Kenji Macfarlane ID:26006480"
date: "22/08/2019"
output: html_document
---

```{r setup, include=FALSE, eval = FALSE, echo = TRUE, tidy = TRUE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
# Load necessary libraries
library(tidyverse)
library(gridExtra)
library(dplyr)
library(caret)
library(xgboost)
library(h2o)
library(pROC)
library(ROCit)
rm(list = ls(all.names = TRUE))
```

This section of code obtains the full set of data by data wrangling for the signal (stops) and background (tops).

1) Stop benchmark 1 $ \tilde{t}= \text{TeV}, \chi_1^0 = \text{GeV} $. 
```{r, message = F}
# Load the data of interest
topData <- read.delim(file = "/home/user1/Desktop/Root files/ttbar1m.txt", sep = ",") 
topData$Signal <-rep(0,nrow(topData))
stopbm1 <- read.delim(file = "/home/user1/Desktop/Root files/benchmark_01.txt", sep = ",") 
stopbm1$Signal <-  rep(1,nrow(stopbm1))

# Remove Electrons and Muons so that we have ONE lepton in each decay
stopbm1_rmv <- stopbm1 %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs

# Remove Electrons and Muons so that we have ONE lepton in each decay
topData_rmv <- topData %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs

# Reduce sample size of stops to match background's (top) sample size
stopbm1 <- stopbm1 %>% anti_join(stopbm1_rmv[sample(seq(nrow(topData_rmv),nrow(stopbm1_rmv), by = 1)),])
rm(stopbm1_rmv, topData_rmv)

# Combine the stop and top data for a complete set
Data_benchmark01 <- rbind.data.frame(stopbm1, topData)
Data_benchmark01 <- Data_benchmark01[sample(nrow(Data_benchmark01)),]
## Free up some space
rm(stopbm1, topData)
```

Split to true training and test set for classification, including the pre-selection criteria (this is met with the delphes card and by choosing ONE lepton and ONLY ONE lepton for the event).
```{r}
# Partition the given data in order to cross validate later
set.seed(sample(1:1000000001, 1, replace=T))
tr_indx <- createDataPartition(Data_benchmark01$Signal, p = 2/3)$Resample1
true_train <- Data_benchmark01[tr_indx, ]
true_test <- Data_benchmark01[-tr_indx, ]

# Remove Electrons and Muons so that we have ONE lepton in each decay
true_train <- true_train %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs
#ttbarlepPT_check <- summary(topData_rmv$Electron.PT_1==topData_rmv$Muon.PT_1) # Check if PT1 for E and M are different at each entry

# Data wrangling with Leptons
true_train <- true_train %>%
  mutate(
  Lepton.PT = Electron.PT_1 + Muon.PT_1,
  Lepton.Eta = Electron.Eta_1 + Muon.Eta_1,
  Lepton.Phi = Electron.Phi_1 + Muon.Phi_1,
  Lepton.Type = as.numeric(replace(Electron.PT_1, Electron.PT_1 > 0, 1)) + # 1 for Electrons
  as.numeric(replace(Muon.PT_1, Muon.PT_1 > 0, 2)), # 2 for Muons
  ) %>%
  select(-grep(pattern="^Electron|^Muon",colnames(true_train)))

# Remove Electrons and Muons so that we have ONE lepton in each decay
true_test <- true_test %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs

# Data wrangling with Leptons
true_test <- true_test %>%
  mutate(
  Lepton.PT = Electron.PT_1 + Muon.PT_1,
  Lepton.Eta = Electron.Eta_1 + Muon.Eta_1,
  Lepton.Phi = Electron.Phi_1 + Muon.Phi_1,
  Lepton.Type = as.numeric(replace(Electron.PT_1, Electron.PT_1 > 0, 1)) + # 1 for Electrons
  as.numeric(replace(Muon.PT_1, Muon.PT_1 > 0, 2)), # 2 for Muons
  ) %>%
  select(-grep(pattern="^Electron|^Muon",colnames(true_test)))

# create a second training-test set pair for cross validation via splitting (0.75) the training set.

set.seed(sample(1:1000000001, 1, replace=T))
tr_indx2 <- createDataPartition(true_train$Signal, p = 0.75)$Resample1
part_train <- true_train[tr_indx2, ]
part_test <- true_test[-tr_indx2, ]
```


Using the h2o package, we can can split the data set into training and test sets
```{r, message=FALSE}
# Run AutoML to find the possibly best model for this
h2o.init()
DD_h2oVer <- as.h2o(Data_benchmark01)
n_seed <- sample(1:1000000001, 1, replace=T)
h_split <- h2o.splitFrame(DD_h2oVer, ratios = 0.75, seed = n_seed)
h_train <- h_split[[1]] # 75% for modelling
h_test <- h_split[[2]]
features <- setdiff(colnames(Data_benchmark01), "Signal")
```



Within the h2o package, there is a function called "h2o.automl" which trains many models in order to obtain the best possible classifier.
Number 1), with a k-fold cross-validation of k=5 and testing 20 models... 
```{r}
automl1 = h2o.automl(x = features,
                    y = "Signal",
                    training_frame = h_train,
                    nfolds = 5,                     # 5-fold Cross-Validation
                    max_models = 20,                # Max number of models
                    stopping_metric = "RMSE",       # Metric to optimize
                    project_name = "automl_stop_search", # Specify a name so you can add more models later
                    seed = n_seed) 
check1 <- automl1@leaderboard
check1
```
Produced a result where a Stacking Ensemble was said to be best.

Number 2), with a k-fold cross-validation of k=10 and testing 100 models... 
```{r}
automl2 = h2o.automl(x = features,
                    y = "Signal",
                    training_frame = h_train,
                    nfolds = 10,                     # 5-fold Cross-Validation
                    max_models = 100,                # Max number of models
                    stopping_metric = "RMSE",       # Metric to optimize
                    project_name = "automl_stop_search", # Specify a name so you can add more models later
                    seed = n_seed) 
check2 <- automl2@leaderboard
check2
```

Number 3), with a k-fold cross-validation of k=10 and testing 200 models... 
```{r}
automl3 = h2o.automl(x = features,
                    y = "Signal",
                    training_frame = h_train,
                    nfolds = 10,                     # 5-fold Cross-Validation
                    max_models = 200,                # Max number of models
                    stopping_metric = "RMSE",       # Metric to optimize
                    project_name = "automl_stop_search", # Specify a name so you can add more models later
                    seed = n_seed) 
check3 <- automl3@leaderboard
check3
```



Build an XGBoost model according to automl (Ensemble methods are not to be considered).
----Testing with the first benchmark set.
```{r}
# Turn each dataset into a suitable xgb matrix
tr_M <- model.matrix(~. + 0, data = part_train %>% select(-Signal))
ts_M <- model.matrix(~. + 0, data = part_test %>% select(-Signal))
xgb_tr <- xgb.DMatrix(data = tr_M, label = part_train$Signal)
xgb_ts <- xgb.DMatrix(data = ts_M, label = part_test$Signal)

bm01_tr <- model.matrix(~. + 0, data = true_train %>% select(-Signal))
xgb_bm01 <- xgb.DMatrix(data = bm01_tr, label = true_train$Signal)
bm01_ts <- model.matrix(~. + 0, data = true_test %>% select(-Signal))
ts_xgbM <- xgb.DMatrix(data = bm01_ts, label = true_test$Signal)


tr_test <- xgb.train(booster = "gbtree", objective = "binary:logistic", data = xgb_bm01, nrounds = 200, max_depth = 6, eval_metric = "merror")
pred_test <- predict(tr_test, ts_xgbM)
for (i in 1:NROW(pred_test)){
  if (pred_test[i] > 0.9){
       pred_test[i] = 1
     } else {
       pred_test[i] = 0
     }
}
confusionMatrix(table(pred_test, true_test$Signal))

# Seems like the objective function doesn't really make a difference.
```

Find the most optimal parameter
```{r}
param <- list(booster = "gbtree", objective = "multi:softmax", num_class = 2)

new_param <- expand.grid(
  nrounds = seq(from = 50, to = 500, by = 50),
  eta = seq(from = 0.1, to = 0.5, by = 0.1),
  max_depth = 4:8, 
  eval_metric = "merror"
)

new_param <- new_param %>%
  mutate(!!! param)

#rm(lepPT_check, ttbarlepPT_check, tr_indx, tr_indx2, Data_benchmark01, stopbm1, stopbm1_rmv, topData, topData_rmv)

# Perform xgboost cv and extract minimum test MSE mean from each xgbcv
xgbcv_result <- matrix(nrow = NROW(new_param), ncol = 2) 

for (i in 1:(NROW(new_param)/5)){
  xgbcv <- 
    xgb.cv(params = new_param[i,], data = xgb_tr, nrounds = new_param[i,1],
           nfold = 10, showsd = T, stratified = T, print_every_n = 10, early_stopping_round = 20,
           maximize = F)
  xgbcv_result[i,1] <- min(xgbcv$evaluation_log$test_merror_mean)
  xgbcv_result[i,2] <- xgbcv$best_iteration
  rm(xgbcv)
}

for (i in (NROW(new_param)/5):(2*NROW(new_param)/5)){
  xgbcv <- 
    xgb.cv(params = new_param[i,], data = xgb_tr, nrounds = new_param[i,1],
           nfold = 10, showsd = T, stratified = T, print_every_n = 10, early_stopping_round = 20,
           maximize = F)
  xgbcv_result[i,1] <- min(xgbcv$evaluation_log$test_merror_mean)
  xgbcv_result[i,2] <- xgbcv$best_iteration
  rm(xgbcv)
}
for (i in (2*NROW(new_param)/5):(3*NROW(new_param)/5)){
  xgbcv <- 
    xgb.cv(params = new_param[i,], data = xgb_tr, nrounds = new_param[i,1],
           nfold = 10, showsd = T, stratified = T, print_every_n = 10, early_stopping_round = 20,
           maximize = F)
  xgbcv_result[i,1] <- min(xgbcv$evaluation_log$test_merror_mean)
  xgbcv_result[i,2] <- xgbcv$best_iteration
  rm(xgbcv)
}

for (i in (3*NROW(new_param)/5):(4*NROW(new_param)/5)){
  xgbcv <- 
    xgb.cv(params = new_param[i,], data = xgb_tr, nrounds = new_param[i,1],
           nfold = 10, showsd = T, stratified = T, print_every_n = 10, early_stopping_round = 20,
           maximize = F)
  xgbcv_result[i,1] <- min(xgbcv$evaluation_log$test_merror_mean)
  xgbcv_result[i,2] <- xgbcv$best_iteration
  rm(xgbcv)
}

for (i in (4*NROW(new_param))/5:NROW(new_param)){
  xgbcv <- 
    xgb.cv(params = new_param[i,], data = xgb_tr, nrounds = new_param[i,1],
           nfold = 10, showsd = T, stratified = T, print_every_n = 10, early_stopping_round = 20,
           maximize = F)
  xgbcv_result[i,1] <- min(xgbcv$evaluation_log$test_merror_mean)
  xgbcv_result[i,2] <- xgbcv$best_iteration
  rm(xgbcv)
}
#### row/list number of the best xgbcv
best_xgbcv <- which.min(xgbcv_result[,1])

best_param <- new_param[best_xgbcv,]

# train on partitioned set
tr_test <- xgb.train(params = best_param, data = xgb_tr, nrounds =xgbcv_result[best_xgbcv,2])
pred_test <- predict(tr_test, xgb_ts)
confusionMatrix(table(pred_test, part_test$Signal))

# train on original training set
bm01_tr <- model.matrix(~. + 0, data = true_train %>% select(-Signal))
xgb_bm01 <- xgb.DMatrix(data = bm01_tr, label = true_train$Signal)

tr_xgb <- xgb.train(params = best_param, 
          data = xgb_bm01, nrounds = xgbcv[[best_xgbcv]]$best_iteration)

# test error after prediction
bm01_ts <- model.matrix(~. + 0, data = bm01_ts %>% select(-Signal))
ts_xgbM <- xgb.DMatrix(data = bm01_ts %>% select(-Signal))
xgbpred <- predict(tr_xgb, ts_xgbM)
```




Using the h2o version to see if it doesn't crash...
```{r}
h2o.init()

true_train[,"Signal"] <- as.factor(true_train[,"Signal"])
true_test[,"Signal"] <- as.factor(true_test[,"Signal"])
part_train[,"Signal"] <- as.factor(part_train[,"Signal"])
part_test[,"Signal"] <- as.factor(part_test[,"Signal"])

true_tr <- as.h2o(true_train, destination_frame = "true_train") 
true_ts <- as.h2o(true_test, destination_frame = "true_test")
part_tr <- as.h2o(true_train[tr_indx2, ], destination_frame = "part_train")
part_ts <- as.h2o(true_test[-tr_indx2, ], destination_frame = "part_test")
  

h2o.xgb_param <- list(
  ntrees = seq(from = 100, to = 500, by = 100),
  learn_rate = seq(from = 0.2, to = 0.6, by = 0.1),
  max_depth = 4:8,
  col_sample_rate = c(0.5, 0.75, 1.0),
  stopping_metric = c("logloss", "mse", "rmse", "rmsle")
)

grid <- h2o.grid("gbm", 
                 x = 1:40, 
                 y = "Signal",
                 grid_id = "grid",
                 training_frame = true_tr,
                 validation_frame = part_ts,
                 nfolds = 10,
                 hyper_params = h2o.xgb_param)

grid_results <- h2o.getGrid(grid_id = "grid", sort_by = "auc", decreasing = TRUE)
best_model <- h2o.getModel(grid_results@model_ids[[1]])
# A test performace shows that RMSE is the best choice as a stopping metric without any other parameters tuned. 
# Will  this change when others are tuned?

# Perform xgboost cv
xgb_h2o <- vector("list", NROW(param)) 
for (i in 1:NROW(param)){
 xgb_h2o[[i]] <- h2o.xgboost(y = "Signal",
                         x = 1:40,
                         training_frame = true_tr,
                         validation_frame = part_ts,
                         model_id = "model",
                         ntrees = param[i,1],
                         learn_rate = param[i,2],
                         max_depth = param[i,3],
                         quiet_mode = TRUE,
                         stopping_rounds = 5,
                         distribution = "bernoulli",
                         score_tree_interval = 1,
                         score_each_iteration = TRUE,
                         nfolds = 10,
                         stopping_metric = param[i,4],
                         fold_assignment = "AUTO",
                         fold_column = NULL,
                         ignore_const_cols = TRUE,
                         offset_column = NULL,
                         weights_column = NULL,
                         keep_cross_validation_models = TRUE,
                         keep_cross_validation_predictions = FALSE,
                         keep_cross_validation_fold_assignment = FALSE,
                         tree_method = "hist",
                         grow_policy = "lossguide",
                         booster = "gbtree",
                         stopping_tolerance = 0.001, 
                         max_runtime_secs = 0, 
                         seed = -1,
                         export_checkpoints_dir = NULL,
                         min_rows = 1, 
                         min_child_weight = 1,
                         sample_rate = 1, 
                         subsample = 1, 
                         col_sample_rate = 1,
                         colsample_bylevel = 1, 
                         col_sample_rate_per_tree = 1,
                         colsample_bytree = 1, 
                         max_abs_leafnode_pred = 0,
                         max_delta_step = 0, 
                         monotone_constraints = NULL, 
                         min_split_improvement = 0, gamma = 0, 
                         nthread = -1, 
                         max_bins = 256, 
                         max_leaves = 0,  
                         min_sum_hessian_in_leaf = 100, 
                         min_data_in_leaf = 0,
                         rate_drop = 0, 
                         one_drop = FALSE, 
                         skip_drop = 0,
                         reg_lambda = 1, 
                         reg_alpha = 0,
                         dmatrix_type = "auto", 
                         backend = "auto",
                         gpu_id = 0, 
                         verbose = FALSE,
                         tweedie_power = 1.5,
                         categorical_encoding = "AUTO"
                         )
}


Preds <- as.data.frame(h2o.predict(xgb_h2o[[1]], true_ts))

confusionMatrix(table(Preds$predict, true_test[1:length(Preds$predict),37]))

```

This section onwards follows from above, but with the other benchmark 

2) Stop benchmark 2 $ \tilde{t}= 1,225 \text{TeV}, \chi_1^0 = 400 \text{GeV} $. 
```{r, message = F}
# Load the data of interest
topData <- read.delim(file = "/home/user1/Desktop/Root files/ttbar1m.txt", sep = ",") 
topData$Signal <-rep(0,nrow(topData))
stopbm2 <- read.delim(file = "/home/user1/Desktop/Root files/benchmark_02.txt", sep = ",") 
stopbm2$Signal <-  rep(1,nrow(stopbm2))

# Remove Electrons and Muons so that we have ONE lepton in each decay
stopbm2_rmv <- stopbm2 %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs

# Remove Electrons and Muons so that we have ONE lepton in each decay
topData_rmv <- topData %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs

# Reduce sample size of stops to match background's (top) sample size
stopbm2 <- stopbm2 %>% anti_join(stopbm2_rmv[sample(seq(nrow(topData_rmv),nrow(stopbm2_rmv), by = 1)),])
rm(stopbm2_rmv, topData_rmv)

# Combine the stop and top data for a complete set
Data_benchmark02 <- rbind.data.frame(stopbm2, topData)
Data_benchmark02 <- Data_benchmark02[sample(nrow(Data_benchmark02)),]
## Free up some space
rm(stopbm2, topData)

# Split to true training and test set for classification, including the pre-selection criteria (this is met with the delphes card and by choosing ONE lepton and ONLY ONE lepton for the event).

# Partition the given data in order to cross validate later
set.seed(sample(1:1000000001, 1, replace=T))
tr_indx <- createDataPartition(Data_benchmark02$Signal, p = 2/3)$Resample1
true_train2 <- Data_benchmark02[tr_indx, ]
true_test2 <- Data_benchmark02[-tr_indx, ]

# Remove Electrons and Muons so that we have ONE lepton in each decay
true_train2 <- true_train2 %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs
#ttbarlepPT_check <- summary(topData_rmv$Electron.PT_1==topData_rmv$Muon.PT_1) # Check if PT1 for E and M are different at each entry

# Data wrangling with Leptons
true_train2 <- true_train2 %>%
  mutate(
  Lepton.PT = Electron.PT_1 + Muon.PT_1,
  Lepton.Eta = Electron.Eta_1 + Muon.Eta_1,
  Lepton.Phi = Electron.Phi_1 + Muon.Phi_1,
  Lepton.Type = as.numeric(replace(Electron.PT_1, Electron.PT_1 > 0, 1)) + # 1 for Electrons
                as.numeric(replace(Muon.PT_1, Muon.PT_1 > 0, 2)), # 2 for Muons
  ) %>%
  select(-grep(pattern="^Electron|^Muon",colnames(true_train2)))

# Remove Electrons and Muons so that we have ONE lepton in each decay
true_test2 <- true_test2 %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs

# Data wrangling with Leptons
true_test2 <- true_test2 %>%
  mutate(
  Lepton.PT = Electron.PT_1 + Muon.PT_1,
  Lepton.Eta = Electron.Eta_1 + Muon.Eta_1,
  Lepton.Phi = Electron.Phi_1 + Muon.Phi_1,
  Lepton.Type = as.numeric(replace(Electron.PT_1, Electron.PT_1 > 0, 1)) + # 1 for Electrons
                as.numeric(replace(Muon.PT_1, Muon.PT_1 > 0, 2)), # 2 for Muons
  ) %>%
  select(-grep(pattern="^Electron|^Muon",colnames(true_test2)))


# create a second training-test set pair for cross validation via splitting (0.75) the training set.
set.seed(sample(1:1000000001, 1, replace=T))
tr_indx2 <- createDataPartition(true_train2$Signal, p = 0.75)$Resample1
part_train2 <- true_train2[tr_indx2, ]
part_test2 <- true_test2[-tr_indx2, ]
```




3) Stop benchmark 3 $ \tilde{t}= 1.25 \text{TeV}, \chi_1^0 = 100 \text{GeV} $. 
```{r, message = F}
# Load the data of interest
topData <- read.delim(file = "/home/user1/Desktop/Root files/ttbar1m.txt", sep = ",") 
topData$Signal <-rep(0,nrow(topData))
stopbm3 <- read.delim(file = "/home/user1/Desktop/Root files/benchmark_03.txt", sep = ",") 
stopbm3$Signal <-  rep(1,nrow(stopbm3))

# Remove Electrons and Muons so that we have ONE lepton in each decay
stopbm3_rmv <- stopbm3 %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs

# Remove Electrons and Muons so that we have ONE lepton in each decay
topData_rmv <- topData %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs

# Reduce sample size of stops to match background's (top) sample size
stopbm3 <- stopbm3 %>% anti_join(stopbm3_rmv[sample(seq(nrow(topData_rmv),nrow(stopbm3_rmv), by = 1)),])
rm(stopbm3_rmv, topData_rmv)

# Combine the stop and top data for a complete set
Data_benchmark03 <- rbind.data.frame(stopbm3, topData)
Data_benchmark03 <- Data_benchmark03[sample(nrow(Data_benchmark03)),]
## Free up some space
rm(stopbm3, topData)


# Split to true training and test set for classification, including the pre-selection criteria (this is met with the delphes card and by choosing ONE lepton and ONLY ONE lepton for the event).

# Partition the given data in order to cross validate later
set.seed(sample(1:1000000001, 1, replace=T))
tr_indx <- createDataPartition(Data_benchmark01$Signal, p = 2/3)$Resample1
true_train3 <- Data_benchmark03[tr_indx, ]
true_test3 <- Data_benchmark03[-tr_indx, ]

# Remove Electrons and Muons so that we have ONE lepton in each decay
true_train3 <- true_train3 %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs
#ttbarlepPT_check <- summary(topData_rmv$Electron.PT_1==topData_rmv$Muon.PT_1) # Check if PT1 for E and M are different at each entry

# Data wrangling with Leptons
true_train3 <- true_train3 %>%
  mutate(
  Lepton.PT = Electron.PT_1 + Muon.PT_1,
  Lepton.Eta = Electron.Eta_1 + Muon.Eta_1,
  Lepton.Phi = Electron.Phi_1 + Muon.Phi_1,
  Lepton.Type = as.numeric(replace(Electron.PT_1, Electron.PT_1 > 0, 1)) + # 1 for Electrons
                as.numeric(replace(Muon.PT_1, Muon.PT_1 > 0, 2)), # 2 for Muons
  ) %>%
  select(-grep(pattern="^Electron|^Muon",colnames(true_train3)))

# Remove Electrons and Muons so that we have ONE lepton in each decay
true_test3 <- true_test3 %>% 
  filter(Muon.PT_1 != "0" | Electron.PT_1 != "0") %>% # select non-zero values
  filter(Muon.PT_1 == 0 | Electron.PT_1 == 0) %>% # select zero values
  filter(Muon.PT_2 == 0, Electron.PT_2 == 0) # Select zero values in second order PTs

# Data wrangling with Leptons
true_test3 <- true_test3 %>%
  mutate(
  Lepton.PT = Electron.PT_1 + Muon.PT_1,
  Lepton.Eta = Electron.Eta_1 + Muon.Eta_1,
  Lepton.Phi = Electron.Phi_1 + Muon.Phi_1,
  Lepton.Type = as.numeric(replace(Electron.PT_1, Electron.PT_1 > 0, 1)) + # 1 for Electrons
                as.numeric(replace(Muon.PT_1, Muon.PT_1 > 0, 2)), # 2 for Muons
  ) %>%
  select(-grep(pattern="^Electron|^Muon",colnames(true_test3)))



# create a second training-test set pair for cross validation via splitting (0.75) the training set.

set.seed(sample(1:1000000001, 1, replace=T))
tr_indx2 <- createDataPartition(true_train3$Signal, p = 0.75)$Resample1
part_train3 <- true_train3[tr_indx2, ]
part_test3 <- true_test3[-tr_indx2, ]
```


Checking how the classifier from benchmark_01 performs against others.
```{r}
# Turn each dataset into a suitable xgb matrix
tr_M2 <- model.matrix(~. + 0, data = part_train2 %>% select(-Signal))
ts_M2 <- model.matrix(~. + 0, data = part_test2 %>% select(-Signal))
xgb_tr2 <- xgb.DMatrix(data = tr_M2, label = part_train2$Signal)
xgb_ts2 <- xgb.DMatrix(data = ts_M2, label = part_test2$Signal)

bm02_tr <- model.matrix(~. + 0, data = true_train2 %>% select(-Signal))
xgb_bm02 <- xgb.DMatrix(data = bm02_tr, label = true_train2$Signal)
bm02_ts <- model.matrix(~. + 0, data = true_test2 %>% select(-Signal))
ts_xgbM2 <- xgb.DMatrix(data = bm02_ts, label = true_test2$Signal)

tr_test2 <- xgb.train(booster = "gbtree", objective = "binary:logistic", data = xgb_bm02, nrounds = 200, max_depth = 6, eval_metric = "merror")
pred_test2 <- predict(tr_test2, ts_xgbM2)

#####pred_test2 <- predict(tr_test, ts_xgbM2)
for (i in 1:NROW(pred_test2)){
  if (pred_test2[i] > 0.9){
       pred_test2[i] = 1
     } else {
       pred_test2[i] = 0
     }
}
confusionMatrix(table(pred_test2, true_test2$Signal))

tr_M3 <- model.matrix(~. + 0, data = part_train3 %>% select(-Signal))
ts_M3 <- model.matrix(~. + 0, data = part_test3 %>% select(-Signal))
xgb_tr3 <- xgb.DMatrix(data = tr_M3, label = part_train3$Signal)
xgb_ts3 <- xgb.DMatrix(data = ts_M3, label = part_test3$Signal)

bm03_tr <- model.matrix(~. + 0, data = true_train3 %>% select(-Signal))
xgb_bm03 <- xgb.DMatrix(data = bm03_tr, label = true_train3$Signal)
bm03_ts <- model.matrix(~. + 0, data = true_test3 %>% select(-Signal))
ts_xgbM3 <- xgb.DMatrix(data = bm03_ts, label = true_test3$Signal)

tr_test3 <- xgb.train(booster = "gbtree", objective = "binary:logistic", data = xgb_bm03, nrounds = 200, max_depth = 6, eval_metric = "merror")
pred_test3 <- predict(tr_test3, ts_xgbM3)

#####pred_test3 <- predict(tr_test, ts_xgbM3)
for (i in 1:NROW(pred_test3)){
  if (pred_test3[i] > 0.9){
       pred_test3[i] = 1
     } else {
       pred_test3[i] = 0
     }
}
confusionMatrix(table(pred_test3, true_test3$Signal))
```

Create ROC curves based on the test models.
```{r}
par(pty = "s")
roc(true_test$Signal, pred_test, 
    plot = TRUE, smoothed = TRUE, legacy.axes = TRUE, percent = TRUE, 
    xlab = "False Positive Rate (FPR)", ylab = "True Positive Rate (TPR)", col = "blue3",
    ci = TRUE, ci.alpha = 0.9, stratified = FALSE,
    auc = TRUE, grid=TRUE, print.auc=TRUE, print.auc.x = 70, print.auc.y = 55, show.thres=TRUE)
plot.roc(true_test2$Signal, pred_test2, ci = TRUE, ci.alpha = 0.9,
         percent = TRUE, print.auc = TRUE, add = TRUE, col = "green4", print.auc.x = 70, print.auc.y = 45)
plot.roc(true_test3$Signal, pred_test3, ci = TRUE, ci.alpha = 0.9,
         percent = TRUE, print.auc = TRUE, add = TRUE, col = "darkmagenta", print.auc.x = 70, print.auc.y = 35)
legend("bottomright", legend=c("Benchmark 1", "Benchmark 2", "Benchmark 3"), col = c("blue3", "green4", "darkmagenta"), pch = 15)

```

```{r}
bm01ROC <- rocit(score = pred_test, class = true_test$Signal)
plot(bm01ROC)
```